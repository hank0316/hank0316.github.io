---
layout: about
title: about
permalink: /
subtitle:

profile:
  align: right
  image: prof_pic.png
  image_circular: false # crops the image to make it circular
  more_info: >

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

MS Student @ [National Taiwan University](https://www.ntu.edu.tw/english/)  
Visiting Research Intern @ [University of Virginia](https://www.virginia.edu/)  
**<font color="#f00">Seeking PhD positions for Fall 2026!</font>**

I am an M.S. student at the Graduate Institute of Networking and Multimedia, National Taiwan University, fortunate to be advised by [Prof. Yun-Nung (Vivian) Chen](https://www.csie.ntu.edu.tw/~yvchen/). I am also currently a visiting research intern at the University of Virginia, advised by [Prof. Yu Meng](https://yumeng5.github.io/).

**Research Focus:** My research centers on natural language processing, particularly Large Language Models (LLMs). I am interested in developing LLMs and agents that are **data-efficient** and **reliable**.

Nowadays, I think about:
1. Language Agents: 
    - How can we make the decision-making process of long-horizon agents more interpretable and faithful?
    - How can we control or reduce unnecessary search and retrieval calls in long-horizon search agents (e.g., DeepResearch-style agents)? How should we quantify and balance the trade-off between reasoning and search?
2. Self-Improving AI systems:
    - What are the necessary conditions for an AI system to reliably self-improve?
    - How can we ensure that such systems remain aligned with human values as they improve beyond the level at which humans can easily provide supervision?
    - How can we efficiently verify the progress of these systems on tasks that require long time horizons and are difficult to evaluate (e.g., scientific research agents)?

<!-- Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](https://fontawesome.com/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->
